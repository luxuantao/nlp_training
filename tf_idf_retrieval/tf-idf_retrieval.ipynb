{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这个实验演示如何使用检索到的信息训练模型用于回答科学测试问题\n",
    "\n",
    "数据和思路参考 github repo [teambetm/allenAI](https://github.com/tambetm/allenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 读 AI2 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo of filters:\n",
      "\t输入字符串:1-hypothesis 2.theory 3--law\n",
      "\t输出字符串:1 hypothesis 2 theory 3 law\n"
     ]
    }
   ],
   "source": [
    "# 去掉文本中的标点和多余的空格\n",
    "filters=set('!\\\"#$%&(),.:;<=>?@[\\\\\\\\]^`{|}~-')\n",
    "filterpunct = lambda s: ''.join([x if x not in filters else ' ' for x in s])\n",
    "filterspace = lambda s: ' '.join(filter(lambda x: len(x)>0, s.split(' ')))\n",
    "\n",
    "demo_s = '1-hypothesis 2.theory 3--law'\n",
    "print('demo of filters:')\n",
    "print('\\t输入字符串:%s' % demo_s)\n",
    "print('\\t输出字符串:%s' % filterspace(filterpunct(demo_s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI2 data, (train, valid, test) 样本数是： (605, 125, 679).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "filename_tr = 'AI2-ScienceQuestions-V2-May2017/MiddleSchool/Middle-NDMC-Train.jsonl'\n",
    "filename_dev = 'AI2-ScienceQuestions-V2-May2017/MiddleSchool/Middle-NDMC-Dev.jsonl'\n",
    "filename_te = 'AI2-ScienceQuestions-V2-May2017/MiddleSchool/Middle-NDMC-Test.jsonl'\n",
    "data, count_AI2 = [], {}\n",
    "\n",
    "id = 0\n",
    "with open(filename_tr, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        id += 1\n",
    "count_AI2['train'] = [0, id-1]\n",
    "\n",
    "with open(filename_dev, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        id += 1\n",
    "count_AI2['dev'] = [count_AI2['train'][-1]+1, id-1]\n",
    "\n",
    "with open(filename_te, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "        id += 1\n",
    "count_AI2['test'] = [count_AI2['dev'][-1]+1, id-1]\n",
    "\n",
    "print('AI2 data, (train, valid, test) 样本数是： (%d, %d, %d).' % \n",
    "      (count_AI2['train'][1] - count_AI2['train'][0]+1,\n",
    "       count_AI2['dev'][1] - count_AI2['dev'][0]+1,\n",
    "       count_AI2['test'][1] - count_AI2['test'][0]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "choices = []\n",
    "solutions = []\n",
    "for s in data:\n",
    "    if len(s['question']['choices']) == 4:\n",
    "        questions.append(filterspace(filterpunct(s['question']['stem'])).lower())\n",
    "        solutions.append(ord(s['answerKey']) - ord('A'))\n",
    "        choices.append([filterspace(filterpunct(s['question']['choices'][i]['text'])).lower() for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples of AI2 questions, solutions and choices:\n",
      "question:\twhich correctly arranges three scientific terms theory law and hypothesis from least to most accepted or tested\n",
      "choices:\t['theory hypothesis law', 'hypothesis law theory', 'theory law hypothesis', 'hypothesis theory law']\n",
      "true choice:\thypothesis theory law\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('examples of AI2 questions, solutions and choices:')\n",
    "i = 0\n",
    "print('question:\\t%s' % questions[i])\n",
    "print('choices:\\t%s' % choices[i])\n",
    "print('true choice:\\t%s\\n' % choices[i][solutions[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 原版问题例子：\n",
    "\n",
    "**问题**:\twhich correctly arranges three scientific termstheory law and hypothesisfrom least to most accepted or tested\n",
    "**选项**:\t['theory hypothesis law', 'hypothesis law theory', 'theory law hypothesis', 'hypothesis theory law']\n",
    "**正确选项**:\thypothesis theory law\n",
    "\n",
    "**问题**:\twhich of these best defines communicable diseases\n",
    "**选项**:\t['they can be cured', 'they are caused by bacteria', 'they are spread to others', 'they can spread only in winter']\n",
    "**正确选项**:\tthey are spread to others\n",
    "\n",
    "**问题**:\ta scientist combines oxygen and hydrogen to form water this combination illustrates that water is\n",
    "**选项**:\t['an atom', 'an element', 'a mixture', 'a compound']\n",
    "**正确选项**:\ta compound\n",
    "\n",
    "**问题**:\tcomparing the skeletons of which of the following fish would best show the evolution of a fish species\n",
    "**选项**:\t['a male fish and a female fish that could produce offspring', 'the same fish just before it received a cut and after it healed', 'a fish that lived recently and a fish that lived a long time ago', 'the same fish just after it hatched and when it was fullgrown']\n",
    "**正确选项**:\ta fish that lived recently and a fish that lived a long time ago\n",
    "\n",
    "**问题**:\twhen oil is burning the reaction will\n",
    "**选项**:\t['only release energy', 'only absorb energy', 'neither absorb nor release energy', 'sometimes release and sometimes absorb energy depending on the oil']\n",
    "**正确选项**:\tonly release energy\n",
    "\n",
    "**问题**:\ttwo pure substances combine to make a new substance the new substance cannot be physically separated and has a different boiling point than each of the original substances this new substance can best be classified as\n",
    "**选项**:\t['an atom', 'a mixture', 'an element', 'a compound']\n",
    "**正确选项**:\ta compound\n",
    "\n",
    "**问题**:\ta change in the environment that causes a response is known as a\n",
    "**选项**:\t['stimulus', 'habit', 'reflex', 'source']\n",
    "**正确选项**:\tstimulus\n",
    "\n",
    "**问题**:\tthe movement of an air mass over earth's surface causes\n",
    "**选项**:\t['earthquake activity', 'local weather changes', 'global warming', 'ecological succession']\n",
    "**正确选项**:\tlocal weather changes\n",
    "\n",
    "**问题**:\tsound will not travel in a\n",
    "**选项**:\t['solid', 'liquid', 'gas', 'vacuum']\n",
    "**正确选项**:\tvacuum\n",
    "\n",
    "**问题**:\twhat is the smallest unit of an element that still has the properties of that element\n",
    "**选项**:\t['an atom', 'a compound', 'an electron', 'a molecule']\n",
    "**正确选项**:\tan atom\n",
    "\n",
    "**问题**:\tin a food pyramid which best explains why the number of organisms decreases from one trophic level to the next\n",
    "**选项**:\t['consumers at the lower level require more energy than the toplevel consumers', 'consumers at the top level require more energy than the lowerlevel consumers', 'the consumers are feeding on larger organisms that have less energy', 'the consumers are feeding on smaller organisms that have less energy']\n",
    "**正确选项**:\tconsumers at the top level require more energy than the lowerlevel consumers\n",
    "\n",
    "### 中文版问题例子：\n",
    "**问题**：哪个正确排列了三个科学术语 - 理论，法律和假设 - 从最少到最接受或测试？\n",
    "**选项**：[“理论，假设，定律”，“假设，定律，理论”，“理论，定律，假设”，“假设，理论，定律”\n",
    "**正确选项**：假设，理论，定律\n",
    "\n",
    "**问题**：哪些最好定义传染病？\n",
    "**选项**：“他们可以治愈”，“它们是由细菌引起的”，“他们传播给他人”，“他们只能在冬天传播”。\n",
    "**正确选项**：他们传播给他人。\n",
    "\n",
    "**问题**：科学家结合氧气和氢气形成水。这个组合说明了水是\n",
    "**选项**：['一个原子'，'一个元素'，'混合物'，'复合物']\n",
    "**正确选项**：一个复合物。\n",
    "\n",
    "**问题**：比较以下鱼类的骨骼最能显示鱼类的进化？\n",
    "**选项**：[“一只可以产生后代的雄鱼和一只雌鱼”，“在接受切割之前的同一条鱼，治愈之后”，最近生活的鱼和长寿的鱼之前“，”孵化后的同样的鱼，当它是完全成长的时候“）\n",
    "**正确选项**：最近生活的鱼和很久以前的鱼\n",
    "\n",
    "**问题**：当油燃烧时，反应会\n",
    "**选项**：“只能释放能量”，“只吸收能量”，“既不吸收也不释放能量”，“有时释放并有时根据油而吸收能量”]\n",
    "**正确选项**：只释放能量\n",
    "\n",
    "**问题**：两种纯物质结合起来制成新物质。新物质不能物理分离，并且具有与每种原始物质不同的沸点。这种新物质最好分类为\n",
    "**选项**：['一个原子'，'混合物'，'一个元素'，'一个复合物']\n",
    "**正确选项**：一个复合物。\n",
    "\n",
    "**问题**：导致响应的环境变化被称为a\n",
    "**选项**：['刺激'，'习惯'，'反射'，'源']\n",
    "**正确选项**：刺激\n",
    "\n",
    "**问题**：空气在地球表面的运动导致\n",
    "**选项**：[“地震活动”，“当地天气变化”，“全球变暖”，“生态继承”]\n",
    "**正确选项**：当地天气变化\n",
    "\n",
    "**问题**：声音不会在一个旅行\n",
    "**选项**：['固体'，'液体'，'气体'，'真空']\n",
    "**正确选项**：真空\n",
    "\n",
    "**问题**：一个元素的最小单元是什么，该元素仍然具有该元素的属性？\n",
    "**选项**：['一个原子'，'一个化合物'，'一个电子'，'一个分子']\n",
    "**正确选项**：一个原子\n",
    "\n",
    "**问题**：在一个食物金字塔中，这最好地解释了为什么有机体的数量从一个营养水平下降到下一个？\n",
    "**选项**：[“下层消费者需要比顶级消费者更多的能量”，“顶级消费者需要比低级消费者更多的能量”，“消费者正在更大量有能量较少的生物体“，”消费者正在食用能量较少的较小生物“。\n",
    "**正确选项**：顶级消费者需要比低层消费者更多的能量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 读 studystack 笔记创建一个小型知识库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'studystack_qa_cleaner_no_qm.txt'\n",
    "defs, terms = [], []\n",
    "with open(name, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        l = line.strip().split('\\t')\n",
    "        defs.append(filterspace(filterpunct(l[1])).lower())\n",
    "        terms.append(filterspace(filterpunct(l[2])).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "知识库中的概念（或答案） 和 定义（或问题）的例子:\n",
      "\n",
      "term (or solution):\treference point\n",
      "definition (or question):\ta place or object used for comparison to determine if an object is in motion must be stationary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('知识库中的概念（或答案） 和 定义（或问题）的例子:\\n')\n",
    "i = 2\n",
    "print('term (or solution):\\t%s' % terms[i])\n",
    "print('definition (or question):\\t%s\\n' % defs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 例子的中文版\n",
    "\n",
    "**运动**：一个物体与另一个物体的距离正在改变的状态\n",
    "\n",
    "**寄生**：一种生物受益并且另一种生物受到损害的共生关系。\n",
    "\n",
    "**全球变暖**：地球二氧化碳过剩平均气温的假设上升\n",
    "\n",
    "**功率=工作除以时间或可以写为p = w / t，可以重新排列为工作=功率时间，或者可以写为W = P * T，再次重新排列时间为时间=功率除以功率 或者可以是T = W / P **：什么是功率方程？\n",
    "\n",
    "**咸水**：（O.Comp。）称为与海水混合的淡水\n",
    "\n",
    "**质量**：什么弥补了事情\n",
    "\n",
    "**蘑菇**：什么是俱乐部真菌的例子？\n",
    "\n",
    "**农业**：种植作物和饲养动物的业务是什么？\n",
    "\n",
    "**固体，液体，气体，等离子体**：四种物质状态\n",
    "\n",
    "**不是由人造的，在环境中自然发生**：什么是自然结构？\n",
    "\n",
    "**数据**：信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考DrQA的方法，使用一个简化的方案做信息检索：\n",
    "1. 建立词典（包括处理停止词汇，过滤样本，提取名词和动词等具体任务）\n",
    "2. 计算每个词语的IDF\n",
    "3. 计算词语在每个样本里面的TF\n",
    "4. 使用score函数选择相关的条目\n",
    "  + 只从studystack里面选择条目\n",
    "  + 使用studystack条目中的Q+A一起计算分数\n",
    "5. 每个样本选择5个条目作为story\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# 过滤停止词汇\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "# 将动词（ing, ed时态）和名词（复数）转化为初始形式\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo, nltk的默认停止词汇:\n",
      "{'not', \"needn't\", 're', 'only', 'weren', 'ain', 'between', 'up', 'with', 'now', 'did', 'before', 'your', 'will', 'below', 'didn', 'shan', 'me', 'she', 'be', 'haven', 'few', 'was', 'hasn', 'most', \"mustn't\", 'are', \"you're\", 'wouldn', 'such', 'his', 'out', \"isn't\", \"weren't\", 'themselves', \"mightn't\", 'which', 'that', 'm', 'herself', 'won', 'y', 'don', 'doesn', 'needn', \"that'll\", 'very', 'both', \"aren't\", 'shouldn', \"it's\", 'and', \"haven't\", 'once', \"couldn't\", 'here', \"should've\", 'couldn', 'just', 'is', 'by', 'there', 'my', 'hers', 'll', \"hadn't\", 'doing', 'can', \"she's\", \"wouldn't\", 'itself', 'to', \"you'll\", \"wasn't\", 'while', 'it', 'any', 'himself', \"shan't\", 'does', 's', 'an', 'when', 'during', 'because', 'isn', 'them', 'ourselves', 'they', 'what', 'so', 'd', 'no', 'their', 'aren', 've', 'who', 'how', 'through', \"hasn't\", 'again', 'wasn', 'other', 'been', 'why', 'yours', 'after', 't', 'further', 'as', 'being', \"you've\", 'those', 'am', 'its', 'for', 'her', 'this', 'yourself', 'these', \"won't\", 'over', 'should', 'had', 'same', 'hadn', 'our', 'if', 'at', 'than', 'myself', 'we', 'ours', 'until', 'all', 'or', 'each', 'him', \"don't\", 'were', 'about', 'o', 'the', 'some', 'where', 'nor', 'own', 'then', 'i', 'a', 'in', 'whom', 'ma', 'you', 'mustn', 'he', 'yourselves', 'on', 'of', 'do', 'mightn', 'has', 'but', \"you'd\", 'above', 'under', 'off', 'down', 'theirs', 'against', 'more', 'from', 'into', 'too', 'having', \"didn't\", \"doesn't\", \"shouldn't\", 'have'}\n"
     ]
    }
   ],
   "source": [
    "print('demo, nltk的默认停止词汇:\\n%s' % stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `textfilter()`: 使用 nltk.pos_tag 提取句子中每一个词语的类型，挑选动词和名词，并使用nltk lemmatizer转化为动词和名词的原始形态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textfilter(text, stopwords, lemmatizer):\n",
    "    text = nltk.pos_tag(text)\n",
    "    text = [w for w in text if w[0] not in stopwords and w[1][:2] in ['NN', 'VB']]\n",
    "    words = []\n",
    "    for w in text:\n",
    "        if w[1].startswith('VB'):\n",
    "            words.append(lemmatizer.lemmatize(w[0], 'v'))\n",
    "        else:\n",
    "            words.append(lemmatizer.lemmatize(w[0], 'n'))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 产生一个和原始数据样本一一对应的数据集，只保留原始形态的名词和动词\n",
    "* `questions + options` : `filter_AI2`\n",
    "* `defs + terms` : `filter_SS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1394/1394 [00:04<00:00, 313.06it/s]\n"
     ]
    }
   ],
   "source": [
    "filter_AI2 = []\n",
    "outliers = []\n",
    "for i in tqdm(range(len(questions))):\n",
    "    try:\n",
    "        text = questions[i].split(' ')\n",
    "        #for j in range(4):\n",
    "        #    text.extend(choices[i][j].split(' '))\n",
    "        filter_AI2.append(textfilter(text, stopwords, lemmatizer))\n",
    "    except:\n",
    "        outliers.append(i)\n",
    "\n",
    "if outliers:\n",
    "    print('过滤掉的一些样本:')\n",
    "    for i in range(min(3, len(outliers))):\n",
    "        print('%s, %s' % (questions[outliers[i]], choices[outliers[i]]))\n",
    "    print('过滤样本...')\n",
    "    for i in outliers[::-1]:\n",
    "        del questions[i]\n",
    "        del choices[i]\n",
    "        del solutions[i]\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 454743/454743 [13:13<00:00, 573.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# 使用 textfilter() 处理studystack的条目\n",
    "filter_SS = []\n",
    "for i in tqdm(range(len(defs))):\n",
    "    text = [x for x in defs[i].split(' ') + terms[i].split(' ') if x]\n",
    "    filter_SS.append(textfilter(text, stopwords, lemmatizer))\n",
    "\n",
    "# 删除一些空样本,即，不包含名词和动词的条目\n",
    "empty_lines = []\n",
    "for i in range(len(filter_SS)):\n",
    "    if len(filter_SS[i]) < 1:\n",
    "        empty_lines.append(i)\n",
    "empty_lines = set(empty_lines)\n",
    "\n",
    "N = len(defs)\n",
    "# studystack后续处理，删除特别短的不包含名词和动词的条目\n",
    "if len(filter_SS[list(empty_lines)[0]]) == 0:\n",
    "    defs =[defs[i] for i in range(N) if i not in empty_lines]\n",
    "    terms = [terms[i] for i in range(N) if i not in empty_lines]\n",
    "    filter_SS = [filter_SS[i] for i in range(N) if i not in empty_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 建立词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. build vocab\n",
    "from collections import Counter\n",
    "c = Counter()\n",
    "for line in filter_AI2:\n",
    "    c.update(line)\n",
    "for line in filter_SS:\n",
    "    c.update(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最常见的100个词语:\n",
      "\t[('cell', 42122), ('water', 24315), ('use', 24127), ('energy', 24054), ('change', 19717), ('make', 19637), ('organism', 18938), ('form', 17789), ('body', 17469), ('plant', 15939), ('system', 14965), ('food', 13260), ('substance', 12988), ('cause', 12917), ('blood', 12850), ('part', 12312), ('process', 12060), ('type', 12036), ('move', 11949), ('object', 11871), ('force', 10645), ('produce', 10382), ('rock', 10151), ('mass', 9983), ('call', 9955), ('animal', 9884), ('air', 9635), ('surface', 9331), ('group', 9251), ('matter', 8877), ('area', 8872), ('material', 8866), ('muscle', 8688), ('earth', 8670), ('gas', 8637), ('time', 8598), ('measure', 8408), ('chemical', 8350), ('thing', 8338), ('element', 8164), ('wave', 7939), ('tissue', 7912), ('atom', 7899), ('bone', 7791), ('find', 7736), ('number', 7678), ('layer', 7668), ('amount', 7462), ('structure', 7147), ('function', 7099), ('particle', 6916), ('disease', 6887), ('molecule', 6834), ('membrane', 6711), ('live', 6640), ('take', 6578), ('contain', 6572), ('temperature', 6528), ('shape', 6471), ('increase', 6420), ('example', 6393), ('heat', 6365), ('control', 6268), ('occur', 6246), ('give', 6134), ('study', 6098), ('protein', 6029), ('oxygen', 5886), ('space', 5812), ('break', 5769), ('movement', 5749), ('state', 5683), ('electron', 5679), ('specie', 5627), ('pressure', 5572), ('sun', 5543), ('nucleus', 5500), ('point', 5469), ('name', 5352), ('result', 5326), ('volume', 5222), ('life', 5217), ('unit', 5189), ('liquid', 5147), ('place', 5130), ('reaction', 5121), ('heart', 5083), ('acid', 5047), ('work', 5038), ('effect', 4868), ('environment', 4853), ('carry', 4842), ('charge', 4827), ('need', 4818), ('factor', 4815), ('base', 4788), ('help', 4690), ('organ', 4681), ('motion', 4648), ('property', 4559)]\n"
     ]
    }
   ],
   "source": [
    "print('最常见的100个词语:\\n\\t%s' % c.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, ivocab = {}, {}\n",
    "id = 0\n",
    "for k, v in c.items():\n",
    "    vocab[k] = id\n",
    "    ivocab[id] = k\n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['arrange', 'term', 'law', 'hypothesis', 'test'],\n",
       " ['state', \"object's\", 'distance', 'change', 'motion'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_AI2[0], filter_SS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 统计IDF\n",
    "N = len(filter_AI2) + len(filter_SS) # 总文档数\n",
    "df = {i: 0 for i in range(len(vocab))}\n",
    "for text in filter_AI2:\n",
    "    for w in set(text):\n",
    "        df[vocab[w]] += 1\n",
    "\n",
    "for text in filter_SS:\n",
    "    for w in set(text):\n",
    "        df[vocab[w]] += 1\n",
    "\n",
    "for i in range(len(vocab)):\n",
    "    df[i] = df[i] / N\n",
    "\n",
    "import math\n",
    "idf = {ivocab[k]: -math.log(v) / math.log(10) for k, v in df.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4343630731481094"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf['organism']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检索样本\n",
    "1. 对每一个`filter_AI2`从`filter_SS`里面检索最接近的5个\n",
    "2. 对每一个`filter_SS`从`filter_SS`里面前后共6000个样本检索最接近的6个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term frequency tf\n",
    "* 词汇$t$在文档$d$中的**term frequency** $tf(t,d)$ 定义为词汇$t$ 在文档 $d$ 中出现的次数\n",
    "* 使用*tf*计算**query-document match scores**的时候，假定query和文档的相关程度不随词频线性增加\n",
    "  + 而是使用词频的log：$w(t,d) = \\log_{10}(1 + tf(t,d))$\n",
    "* 计算query和document的相关程度时，对同时出现在query和document中的词汇的词频加和:$score = \\sum_{t \\in q \\cap d} \\log_{10}(1 + tf(t,d))$\n",
    "* 如果query中的词语在一个文档中没有出现，那么query和这个文档的相关程度为0\n",
    "\n",
    "### Document frequency:  *idf* 权重\n",
    "* 常见词语的信息量往往小于不常见的词语，例如\n",
    "  + 停止词汇的信息量往往很小\n",
    "  + 稀有词汇可能对于文档检索非常有用：query中有一个稀有词汇*arachnocentric*，那么包含*arachnocentric*的文档很可能是有用的文档\n",
    "* 如何量化词汇的权重？\n",
    "  + $df(t)$ 是词汇$t$的 **document frequency** of $t$，即包含词汇$t$的文档的数量\n",
    "  + 使用处理后的$df$倒数，$idf(t) = \\log_{10}\\frac{N}{df(t)}$，描述词汇$t$的权重或信息量（informativeness）\n",
    "\n",
    "### tf-idf 分数\n",
    "* $ W(t,d) = \\log(1+tf(t,d))\\times \\log_{10}(\\frac{N}{df(t)})$\n",
    "* $ score(q,d) = \\sum_{t\\in q\\cap d} w(t,d)$\n",
    "* 这个score用来在检索时排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些辅助变量，方便计算tf\n",
    "filter_SS_dict = []\n",
    "for line in filter_SS:\n",
    "    filter_SS_dict.append(Counter(line))\n",
    "    \n",
    "# 计算基于tfidf的matching score\n",
    "def calc_score(idf, q, list_d, dict_d):\n",
    "    s = set(q).intersection(set(list_d))\n",
    "    score = 0\n",
    "    if len(s) > 0:\n",
    "        for w in s:\n",
    "            score += math.log(1 + dict_d[w]) * idf[w]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 为每个问题（和备选答案）挑选对应的知识库条目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1394/1394 [16:58<00:00,  1.37it/s]\n"
     ]
    }
   ],
   "source": [
    "idx_AI2 = []\n",
    "\n",
    "for i in tqdm(range(len(filter_AI2))):\n",
    "    idx_AI2.append([])\n",
    "    scores = []\n",
    "    for j in range(len(filter_SS)):\n",
    "        scores.append(calc_score(idf, filter_AI2[i], filter_SS[j], filter_SS_dict[j]))\n",
    "    values = np.array(scores)\n",
    "    for k in range(5):\n",
    "        idx_AI2[-1].append(np.argmax(values))\n",
    "        values[idx_AI2[-1][-1]] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: which correctly arranges three scientific terms theory law and hypothesis from least to most accepted or tested\n",
      "\t0:make observations form a hypothesis perform experiments to confirm hypothesis hypothesis is now a theory perform many experiments over several years theory is now a law put into their proper order a theory is now a law b hypothesis is now a theory c make observations d perform experiments to confirm the hypothesis e form a hypothesis f perform many experiments over several years\n",
      "\t1:make observations form a hypothesis perform experiments to confirm hypothesis hypothesis is now a theory perform many experiments over several years theory is now a law put into their proper order a theory is now a law b hypothesis is now a theory c make observations d perform experiments to confirm the hypothesis e form a hypothesis f perform many experiments over several years\n",
      "\t2:after a hypothesis is made scientists will design an experiment to test the hypothesis what is done when testing a hypothesis\n",
      "\t3:hypothesis testing creation of a hypothesis testing analyzing data accept or reject hypothesis\n",
      "\t4:by using a animal cell instead of a plant cell how could you change the test scientist used for testing scheilden's hypothesis to test theodor's hypothesis\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print('question: %s' % questions[i])\n",
    "for j in range(5):\n",
    "    print('\\t%d:%s' % (j, terms[idx_AI2[i][j]] + ' ' + defs[idx_AI2[i][j]]))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题：从最小到最接受或测试，正确地排列了三个科学术语理论定律和假设\n",
    "0：使观察形成一个假设进行实验来证实假设假设现在是一个理论进行了许多实验，几年来的理论现在是一个法律放在正确的秩序中一个理论现在是一个法律b假设现在是一个理论c做观察d执行实验证实假设f形成假设f在几年内执行许多实验\n",
    "1：将观察结果作为假设进行实验以证实假设假设现在是一个理论，在几年内进行了许多实验理论是现在一个法律放在正确的秩序中一个理论现在是一个法律b假设现在是一个理论，实验证实假设f形成假设f在几年内执行许多实验\n",
    "2：定义反例假设理论反例是与科学结论相矛盾的一个例子，一个假设是一个受过教育的猜测，试图解释观察或回答一个问题的理论是一个已经用大量理论测试的假设\n",
    "3：科学理论与科学法不同，因为科学法在自然界中描述了一种观察模式，而不试图解释科学理论作为一个经过良好测试的解释，科学理论与科学定律如何不同\n",
    "4：基于你的想法结论理论的思想假设理解从假设到结论到理论到法律的越来越有效\n",
    "\n",
    "\n",
    "问题：哪些最好定义传染病\n",
    "0：你必须通过停止他们的死亡来恢复黑质神经元，使新的黑质神经元干细胞移植目前正在完成黑质神经元的干细胞移植，但是新的神经元仍然会再次死亡，因此延长了治疗，但没有治愈，但药物合用显着提高了质量的帕金森病患者的生命，但仍然无法治愈疾病**如何治愈**有没有目前的治疗方法，这样做\n",
    "1：感冒和脊髓灰质炎感冒冷咳和打喷嚏鼻病毒或腺病毒无法治疗可以治疗咳嗽脊髓灰质炎脊髓灰质炎病毒肌肉无力和瘫痪症状无法治愈疫苗从粪便或手到嘴巴传播\n",
    "2：水痘和天花水痘水痘病毒瘙痒/瘙痒疹疮疮高烧腹痛模糊病感觉无法治疗可以治疗由天花天花病毒传播的症状小瘙痒斑点高烧死亡无治愈疫苗通过接触传播\n",
    "3：流行性感冒，因为它在一个地理区域发生，然后传播给其他人流感病毒来源于东南亚，并传播到包括美国和欧洲在内的国家感染全世界数百万人的传染病称为\n",
    "4：莱姆病导致病媒传染病在我们身上的症状是流感，像流氓皮疹一样称为红斑，未经治疗可以传播到其他身体系统引起的细菌称为螺旋体\n",
    "\n",
    "\n",
    "问题：科学家结合氧气和氢气来形成水，这种组合说明了水\n",
    "0：分子可以由两个或更多个相同元素的原子组成，如氢气2个氢原子或两个或多个连接在一起的不同元素的原子，如水2个氢原子和1个氧原子\n",
    "1：下标下标是用于告诉您在方程式中存在多少个元素原子的数字，水h20具有2个氢原子，一个氧气•葡萄糖c6h12o6具有6个碳原子的12个氢气和6个氧气\n",
    "2：化合物2个或更多个元素结合在一起以产生分子•相同物质的化合物具有相同的化学成分相同的化学成分水是氢氧原子与1个氧原子键合的盐•来自盐 - 水 - 二氧化碳 - 二氧化碳\n",
    "3：将两个或多个不同元素的原子连接在一起，如水2个氢原子和1个氧原子\n",
    "4：将h2o中的两种或多种元素的组合化合为含有氢和氧的元素的化合物\n",
    "\n",
    "\n",
    "问题：比较下列哪种鱼类的骨骼最能显示鱼类的进化\n",
    "0：列表支持理论演化化石记录的3件证据显示物种dna的变化可以显示如果不同的物种是密切相关的类似结构与生物动物的结构相比寻找相似性\n",
    "1：塑造一种化石，可以帮助身体展现出很久以前生活的鱼类____\n",
    "2：比较和对比一个缅甸蟒蛇和一个园林蜗牛的生命周期，因为他们既生鸡蛋，也不是鸡蛋孵卵，因为鸡蛋孵出后，自己放下鸡蛋后的蜗牛叶，蟒蛇等待直到鸡蛋孵化\n",
    "3：物种概念不同的种类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对每一个选项，计算选项和 support facts 的相关程度\n",
    "wrong = 0\n",
    "for i in range(len(questions)):\n",
    "    q = questions[i]\n",
    "    c = choices[i]\n",
    "    s = solutions[i]\n",
    "    scores = []\n",
    "    for j in range(4):\n",
    "        choice = textfilter(c[j].split(), stopwords, lemmatizer)\n",
    "        score = 0\n",
    "        for k in idx_AI2[i]:\n",
    "            score += calc_score(idf, choice, filter_SS[k], filter_SS_dict[k])\n",
    "        scores.append(score)\n",
    "    if scores[s] < max(scores):\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "among 1394 questions, 950 are correctly classified\n",
      "accuracy: 0.681492\n"
     ]
    }
   ],
   "source": [
    "print('among %d questions, %d are correctly classified' % (len(questions), len(questions)-wrong))\n",
    "print('accuracy: %f' % (1-wrong/len(questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
